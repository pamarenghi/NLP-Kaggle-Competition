# Language Classification Competition - Kaggle

This repository contains all the code, models, and results related to our participation in the **[Kaggle language classification competition](https://www.kaggle.com/competitions/nlp-cs-2025)**.  
The goal of the competition is to classify the language of given text samples.

## Repository Structure

The repository is organized as follows:

  - `data/`:  # Contains the datasets provided by Kaggle
      - `train_submission.csv`: "Training data with labels"
      - `test_without_label.csv`: "Test data without labels"

  - `data_viz.py`: 
      - description: "Exploratory data analysis script for train data"
      - details: "This script checks for NaN values, outliers, and visualizes class distribution"

  - `models/`:  # Contains subfolders for different models
      - `BERT/`: "BERT model training, validation & inference scripts"
      - `FastText/`: "FastText model training, validation & inference scripts"
      - `logistic_regression/`: "Logistic Regression model training, validation & inference scripts"
      - `naive_bayes/`: "Naive Bayes model training, validation & inference scripts"

  - `results/`:
      - description: "Stores the prediction files (CSV) for each model"
      - details: "Each CSV file can be submitted directly to Kaggle"
  
  - `ANLP_Competition_2025_report.pdf`:
      - description: "Report of the work"

  - `README.md`: "Current file"


## Workflow

1. **Data Exploration (`data_viz.py`)**
   - The `data_viz.py` script performs exploratory data analysis (EDA) on `train_submission.csv`.
   - It checks for:
     - Missing values (NaN)
     - Outliers
     - Class distribution

2. **Model Training and Validation**
   - Each model has its own dedicated folder under `models/`.
   - Each folder contains:
     - A **training script** that trains the model using `train_submission.csv`.
     - During training, a **validation step** is performed by splitting the training data into train and validation subsets.
     - Model-specific preprocessing is also handled in these scripts.

3. **Test Data Labeling**
   - Each model folder contains an **inference script**.
   - These scripts take `test_without_label.csv` as input, predict the language for each sample, and output a **CSV file** compatible with Kaggle submission.

4. **Results**
   - All prediction files are stored in the `results/` folder.
   - Each CSV file follows the required Kaggle format and can be directly submitted for evaluation.
   - Each submission helps track the **accuracy** of different models and compares them with other participants.


## Models Implemented

- **BERT**
- **FastText**
- **TFIDF + Logistic Regression**
- **TFIDF + Naive Bayes**


## Submission to Kaggle

Each prediction CSV generated by the models is stored in `results/` and can be directly uploaded to the Kaggle competition platform for evaluation. This allows comparing the performance of different approaches and selecting the best-performing model.


## Authors

Created by Paul-Alexandre MARENGHI, Clément VERON, Ambroise MARTIN ROUVILLE, Théo MICHEL, Edouard SEGUIER
